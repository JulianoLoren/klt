{
  "uuid" : "55341066-e38b-da5e-4151-f67cb2a41819-01",
  "last_modified" : 1581655330839,
  "version" : "3.0.0.20500",
  "content" : "total input rows = 841790\nexpected input rows per mapper = 1000000\nnum reducers for RedistributeFlatHiveTableStep = 1\nRedistribute table, cmd: \nhive -e \"set mapred.job.name='Redistribute Flat Hive Table';\nUSE default;\n\nset mapreduce.job.reduces=1;\n\nset hive.merge.mapredfiles=false;\n\nINSERT OVERWRITE TABLE \\`kylin_intermediate_cube_sale_clone_6ae43d0a_66c7_a8a4_9841_f5256c53d7a4\\` SELECT * FROM \\`kylin_intermediate_cube_sale_clone_6ae43d0a_66c7_a8a4_9841_f5256c53d7a4\\` DISTRIBUTE BY KDN_ORDER_DETAILS_ID,KDN_ORDER_DETAILS_ORDER_ID,KDN_ORDER_DETAILS_PRODUCT_ID;\n\n\" --hiveconf hive.merge.mapredfiles=false --hiveconf hive.auto.convert.join=true --hiveconf dfs.replication=2 --hiveconf hive.exec.compress.output=true --hiveconf hive.auto.convert.join.noconditionaltask=true --hiveconf mapreduce.job.split.metainfo.maxsize=-1 --hiveconf hive.merge.mapfiles=false --hiveconf hive.auto.convert.join.noconditionaltask.size=100000000 --hiveconf hive.stats.autogather=true\nls: cannot access /home/admin/spark-2.3.1-bin-hadoop2.6/lib/spark-assembly-*.jar: No such file or directory\n\nLogging initialized using configuration in jar:file:/home/admin/apache-hive-1.2.1-bin/lib/hive-common-1.2.1.jar!/hive-log4j.properties\nOK\nTime taken: 1.314 seconds\nQuery ID = root_20200214043349_e4e5d22b-0aa4-4d3b-bd22-6d095b032816\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Defaulting to jobconf value of: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nStarting Job = job_1581647538653_0045, Tracking URL = http://ip-172-31-15-241.ap-east-1.compute.internal:8088/proxy/application_1581647538653_0045/\nKill Command = /home/admin/hadoop-2.7.0/bin/hadoop job  -kill job_1581647538653_0045\nHadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n2020-02-14 04:41:33,731 Stage-1 map = 0%,  reduce = 0%\n2020-02-14 04:41:43,138 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 8.02 sec\n2020-02-14 04:41:46,219 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 12.02 sec\n2020-02-14 04:41:47,246 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.33 sec\n2020-02-14 04:41:56,604 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 22.68 sec\n2020-02-14 04:42:06,976 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.34 sec\nMapReduce Total cumulative CPU time: 33 seconds 340 msec\nEnded Job = job_1581647538653_0045\nLoading data to table default.kylin_intermediate_cube_sale_clone_6ae43d0a_66c7_a8a4_9841_f5256c53d7a4\nTable default.kylin_intermediate_cube_sale_clone_6ae43d0a_66c7_a8a4_9841_f5256c53d7a4 stats: [numFiles=0, numRows=841790, totalSize=0, rawDataSize=102867819]\nMapReduce Jobs Launched: \nStage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 33.34 sec   HDFS Read: 98573090 HDFS Write: 98560221 SUCCESS\nTotal MapReduce CPU Time Spent: 33 seconds 340 msec\nOK\nTime taken: 501.072 seconds\n",
  "status" : "SUCCEED",
  "info" : {
    "startTime" : "1581654822203",
    "yarn_application_tracking_url" : "http://ip-172-31-15-241.ap-east-1.compute.internal:8088/proxy/application_1581647538653_0045/",
    "source_records_size" : "98573090",
    "hdfs_bytes_written" : "0",
    "endTime" : "1581655330834"
  }
}